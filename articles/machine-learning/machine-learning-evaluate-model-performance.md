---
ms.openlocfilehash: af93d467463a0fdbf8c0e35fadf8858208fee4e3
ms.sourcegitcommit: bab1265d669c3e6871daa7cb8a5640a47104947a
translationtype: MT
---
<properties 
    pageTitle="评估在机器学习中的模型性能 |Microsoft Azure" 
    description="解释如何评估在 Azure 机器学习中的模型性能。" 
    services="machine-learning"
    documentationCenter="" 
    authors="garyericson" 
    manager="paulettm" 
    editor="cgronlun"/>

<tags 
    ms.service="machine-learning" 
    ms.workload="data-services" 
    ms.tgt_pltfrm="na" 
    ms.devlang="na" 
    ms.topic="article" 
    ms.date="07/14/2015" 
    ms.author="bradsev;garye" />


# 如何评估在 Azure 机器学习中的模型性能

本主题演示如何评估 Azure 机器学习 Studio 中模型的性能，并为此任务提供可用指标的简要说明。 提供三种常见的监察的教育方案︰ 

* 回归
* 二进制的分类 
* multiclass 分类

[AZURE.INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]


评估模型的性能是一种在数据科学过程的核心阶段。 它表明如何成功评分 （预测） 的数据集已通过培训模型。 

Azure 机器学习支持通过其主要机器学习模块的两个模型计算︰[计算模型][计算模型]和[交叉验证模型][跨验证模型]。 这些模块允许您查看您的模型如何执行方面大量的机器学习和统计中常用的指标。

##评估与交叉验证##
评估和交叉验证的标准方法来测量模型的性能。 它们都生成评估指标，可以检查或与那些其他模型进行比较。

[评估模式][评估模型]预计分数数据集作为输入 （或 2 种情况下您想要比较 2 的不同型号的性能）。 这意味着您需要训练使用[训练模型][火车模型]模块模型上使用[分数模型][评分模型]模块，可以评估结果之前某些数据集进行预测。 计算是根据分数和真正标志，所有这些都由[评分模型]的[分数模型]模块输出标签/概率。

或者，您可用于交叉验证执行大量的训练成绩评估操作 （10 个折痕） 自动输入数据的不同子集上。 输入的数据被划分为 10 个部件，其中一个被保留用于测试和其他 9 个培训。 此过程将重复 10 次，并评估指标的平均值。 这有助于确定如何更好地模型将一般化到新的数据集。 [交叉验证模型][跨验证模型]模块接受未经培训的模型和一些带标签的数据集，并将评估结果每 10 个折痕，除了平均结果的输出。

在下面的章节中，我们将构建简单的回归和分类模型，并计算它们的性能，使用[计算模型][计算模型]和[交叉验证模型][跨验证模型]模块。

##计算回归模型##
假设我们想要预测尺寸、 动力、 引擎规格等一些功能的使用的一辆汽车的价格。 这是一个典型的回归问题，其中目标变量 （*价格*） 是一个连续的数字值。 我们可以容纳的简单线性回归模型，给定特定汽车的特征可以预测那辆车的价格。 这种回归模型可以用于成绩我们培训的同一数据集。 一旦我们有了所有汽车的预测的价格，我们可以通过看一看多少预测偏离实际价格平均计算模型的性能。 为说明这一点，我们使用在 Azure 机器学习 Studio 中**保存数据集**部分*汽车价格数据 (Raw) 数据集*可用。
 
###创建实验###
添加到您的工作区在 Azure 机器学习 Studio 以下模块︰

- 汽车的价格数据 (Raw)
- [线性回归][线性回归]
- [火车模型][火车模型]
- [分数模型][分数模型]
- [评估模式][评估模型]


连接端口，如图 1 所示，将[训练模型][火车模型]模块标签列设置为*价格*。
 
![计算回归模型](media/machine-learning-evaluate-model-performance/1.png)

图 1。 评价的回归模型。

###检查评估结果###
运行试验之后, 您可以[计算模型][计算模型]模块的输出端口上单击，并选择查看计算结果的*可视化*。 用回归模型的评估指标是︰*意味着绝对错误*、*根意味着绝对错误*、*相对绝对错误*、*相对平方的错误*和*系数的确定*。

术语"错误"此处表示预测的值和真实值之间的差异。 绝对值或平方的这种差异通常计算若要跨所有情况下，捕获错误的总幅度为预测和真实值之间的差异可能是在某些情况下负。 错误指标测量平均偏差为 true 值从其预测回归模型的预测性能。 较低的错误值意味着该模型做出的预测更准确。 跃点数的整体错误值为 0 表示该模型完全适合的数据。

系数的确定，即所谓的 R 平方值，也是一种标准的方法来测量模型如何更好地适合的数据。 它可以被解释为解释模型的变体的比例。 更高比例是更好的在这种情况下，其中 1 表示再合适不过。
 
![线性回归计算度量值](media/machine-learning-evaluate-model-performance/2.png)

图 2。 线性回归计算指标。

###使用交叉验证###
如前所述，您可以执行重复的培训、 评分和使用[交叉验证模型][跨验证模型]模块自动评估。 在这种情况下需要的只是数据集、 未经培训的模型和[交叉验证模型][跨验证模型]模块 （见下图）。 请注意，您需要设置标签列*价格*[交叉验证模型]中[交叉验证模型]模块的属性。

![交叉验证的回归模型](media/machine-learning-evaluate-model-performance/3.png)

图 3。 交叉验证的回归模型。

运行试验之后, 您可以通过单击右输出端口的[交叉验证模型][跨验证模型]模块上检查评估结果。 这将为每次迭代 （折） 和每个度量标准 (图 4) 的平均的结果提供测量数据的详细的视图。
 
![交叉验证结果的回归模型](media/machine-learning-evaluate-model-performance/4.png)

图 4。 交叉验证的回归模型的结果。

##评估一个二进制分类模型##
在二进制分类方案中，目标变量有只有两种可能的结果，例如: {0，1} 或 {假、 真}，{负，正}。 假设您有一些成人的雇员的数据集人口统计和雇用变量，并要求您在可预测的收入水平，二进制变量的值 {"< = 50 K"，"> 50 K"}。 换句话说，否定类表示使小于或等于 50 K，每年的员工，肯定类表示所有其他员工。 如下所示的回归方案中，我们将培训模型、 分数某些数据，并评估结果。 主要的区别是 Azure 机器学习所计算的度量值和输出的选择。 为了说明收入等级预测方案，我们将使用[成人](http://archive.ics.uci.edu/ml/datasets/Adult)的数据集创建一个 Azure 机器学习实验和计算的两类物流回归模型，常用的二进制分类器的性能。

###创建实验###
添加到您的工作区在 Azure 机器学习 Studio 以下模块︰

- 成人人口普查收入二元分类数据集
- [两类物流回归][两类-物流回归]
- [火车模型][火车模型]
- [分数模型][分数模型]
- [评估模式][评估模型]

连接端口，如图 5 所示，将[训练模型][火车模型]模块标签列设置为*收入*。

![评估一个二进制分类模型](media/machine-learning-evaluate-model-performance/5.png)

图 5。 评估一个二进制分类模型。

###检查评估结果###
运行试验之后, 您可以[计算模型][计算模型]模块的输出端口上单击，并选择*可视化*查看计算结果 (图 7)。 可用的二进制分类模型评估指标是︰*准确*、*精度*、*撤回*、 *F1 分数*和*AUC*。 此外，模块输出混淆矩阵显示真阳性、 漏报、 误报，和真正的否定，以及*台湾*、*精度/撤回*，并*提起*曲线的数量。

准确性是只占的正确分类的实例。 它通常是评估分类器时，您看一下第一个指标。 但是，测试数据时失去了平衡 （其中大部分实例属于一个类），或更感上任一类性能，准确性并不真正捕获分类器的效率。 在收入级别分类方案中，假定正在测试对某些数据，其中 99%的实例表示小于或等于 50 K 每年获得的人。 也可以通过预测类达到 0.99 准确性"< = 50 K"的所有实例。 该分类器在这种情况下似乎做得不错整体，但实际上，它无法正确分类的 high-income 人 （1%)。

因此，最好先计算额外捕捉更具体的评估方面的指标。 在之前进入这类指标的详细信息，是一定要了解混淆矩阵的二元分类评估。 训练集的类标签可以在只有 2 可能的值，我们通常指为正数或负数。 分类器预测正确的正负实例分别称为真阳性 (TP) 和真底片 (TN)。 同样，错误分类的实例称为 (FP) 的误报和漏报 (FN)。 混淆矩阵是只显示属于各 4 类的实例数的表。 Azure 机器学习自动确定该数据集中的两个类是正的类。 如果类标签是布尔值或整数，然后真或"1"标记的实例分配正类。 如果标签都是字符串，如下所示的收入数据集的情况下，标签的字母顺序排序，选择第一层是负的类，而第二级别是正的类。

![二元分类混淆矩阵](media/machine-learning-evaluate-model-performance/6a.png)

图 6。 二元分类混淆矩阵。

回到收入分类问题，我们想要问几个评估问题，帮助我们了解使用分类器的性能。 非常自然的一个问题是: 从其模型预计将获得的个人 > 50 K (TP + FP) 被正确归类多少 (TP)？ 可以通过查看**精确**的模型，它是进行正确分类的阳性比例回答这问题︰ TP/(TP+FP)。 另一个常见的问题是，"所有高出赢取员工收入 > 50 k (TP + FN)，多少未分类器分类正确 (TP)"。 这是实际上**撤回**，或真正率︰ TP/(TP+FN) 分类器。 您可能会注意到，没有明显的平衡之间的精度和召回。 例如，给出一个相对平衡的数据集，分类器预测大部分正情况下，会有高的召回，但会导致大量的假阳性错误尽可能多的负实例而不是低精度的分类。 若要查看这些两种尺度的而异的绘图，您可以单击评估结果的输出页中的精度撤回操作曲线上 （进左上部分的图 7）。

![二元分类评估结果](media/machine-learning-evaluate-model-performance/7.png)图 7。 二元分类的评估结果。

另一个相关的度量标准，通常用是**F1 分数**，采用精度和考虑撤回。 它是这些 2 的度量标准的调和平均值的计算，因此计算︰ F1 = 2 （精度 x 撤回） / （精度 + 召回）。 F1 分数是一个好的方法，以总结求值是一个数字，但它始终是最好看的精度和召回在一起更好地了解一个分类器的行为方式。

此外，一个可以检查与误报率之所以在**接收器操作特征 （台湾）**曲线和相应的**区域在下曲线 (AUC)**值 true 正率。 此曲线越接近左上角，越好的分类器的性能是 （，最大限度地满足正率同时尽量减少误报率之所以）。 那些靠近绘图，从分类器往往会做出接近随机猜测的预测结果的对角线的曲线。

###使用交叉验证###
如下所示的回归示例中，我们可以执行交叉验证进行反复训练，成绩和自动评估不同的数据子集。 同样，我们可以使用[交叉验证模型][跨验证模型]模块、 未经培训物流的回归模型和一个数据集。 标签列必须设置为[交叉验证模型][跨验证模型]模块的属性中的*收入*。 之后运行实验，并单击右输出端口的[交叉验证模型][跨验证模型]模块上，我们可以看到每个折，除了平均值和标准偏差的每个二进制分类指标值。 
 
![交叉验证的二元分类模型](media/machine-learning-evaluate-model-performance/8.png)

图 8。 交叉验证的二元分类模型。

![交叉验证结果的二进制类元](media/machine-learning-evaluate-model-performance/9.png)

图 9。 交叉验证的二元分类器的结果。

##Multiclass 分类模型评估##
本实验中我们将使用流行的[虹膜](http://archive.ics.uci.edu/ml/datasets/虹膜"Iris")数据集包含的鸢尾花植物的 3 不同类型 （类） 的实例。 有 4 功能值 （花萼长度/宽度和花瓣长度/宽度） 为每个实例。 在以前的实验中我们接受培训和测试使用同一个数据集的模型。 在这里，我们将使用[拆分][拆分]模块创建 2 的数据子集，在第一天，训练和成绩评估第二页上。 Iris 数据集公开提供[提示您机器学习资源库](http://archive.ics.uci.edu/ml/index.html)，并可以使用[读取器][读取器]模块下载。

###创建实验###
添加到您的工作区在 Azure 机器学习 Studio 以下模块︰

- [读取器][读取器]
- [Multiclass 决定林][multiclass-决策-林]
- [拆分][拆分]
- [火车模型][火车模型]
- [分数模型][分数模型]
- [评估模式][评估模型]

将端口的连接，如图 10 中所示。

[训练模型][火车模型]模块的标签列索引设置为 5。 数据集有没有标题行，但是我们知道类标签是在第五列中。

[读取器][读取器]模块上单击并将*数据源*属性设置为*通过 HTTP 的 Web URL*和 http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data 指向的*URL* 。

设置要使用的实例的分数中[拆分][拆分]模块 (例如 0.7) 的培训。
 
![评估 Multiclass 分类器](media/machine-learning-evaluate-model-performance/10.png)

图 10。 评估 Multiclass 分类器

###检查评估结果###
运行试验并单击[计算模型][计算模型]的输出端口上。 评估结果显示形式的混淆矩阵，在这种情况下。 该矩阵显示的实际与预测的所有 3 个类的实例。
 
![Multiclass 分类评估结果](media/machine-learning-evaluate-model-performance/11.png)

图 11。 Multiclass 分类的评估结果。

###使用交叉验证###
如前所述，您可以执行重复的培训、 评分和使用[交叉验证模型][跨验证模型]模块自动评估。 您将需要一个数据集、 未经培训的模型和[交叉验证模型][跨验证模型]模块 （见下图）。 再次，您需要设置[交叉验证模型][跨验证模型]模块 （列索引 5 在本例中） 的标签列。 运行试验并单击鼠标右键输出端口的[交叉验证模型][跨验证模型]后，您可以检查每个折以及平均值和标准偏差的度量值。 此处显示的度量标准是类似于所述的二元分类情况。 但是，请注意，multiclass 的分类、 计算 true 的阳性底片和正片/漏报通过计算基于每个类，因为没有任何整体正的或负的类。 例如，如果计算精度或撤回 Iris setosa 类的则假定这是正的类和其他所有为负。
 
![交叉验证 Multiclass 分类模型](media/machine-learning-evaluate-model-performance/12.png)

图 12。 交叉验证 Multiclass 分类模型。


![Multiclass 分类模型的交叉验证结果](media/machine-learning-evaluate-model-performance/13.png)

图 13。 Multiclass 分类模型的交叉验证结果。


<!-- Module References -->
[交叉验证模型]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[评估模型]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[线性回归]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-决策-林]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[读取器]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[分数模型]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[拆分]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[火车模型]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[两类-物流回归]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/
 
测试
